package com.sf.spark.streaming

import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.streaming.{Seconds, State, StateSpec, StreamingContext}

import scala.collection.mutable

/**
  * Created by suibianda LGD  on 2019/1/21 15:01
  * Modified by: 
  * Version: 0.0.1
  * Usage: 
  *
  */
object SparkStreamingWordCount {
  def main(args: Array[String]): Unit = {
    
    /**
      * 设置checkpoint目录
      */
    val checkpointDir = "spark/CheckPointDir"
    
    def createStreamingContext():StreamingContext={
      // 首先配置一下本 quick example 将跑在本机，app name 是 NetworkWordCount
      val conf = new SparkConf().setMaster("local[2]").setAppName("NetworkWordCount")
      // batchDuration 设置为 1 秒，然后创建一个 streaming 入口
      val sc = new SparkContext(conf)
      sc.setLogLevel("WARN")
      val ssc = new StreamingContext(sc, Seconds(30))
      ssc.checkpoint(checkpointDir)

      // ssc.socketTextStream() 将创建一个 SocketInputDStream；这个 InputDStream 的 SocketReceiver 将监听本机 9999 端口
      val lines = ssc.socketTextStream("localhost", 9999)

      val words = lines.flatMap(_.split(" "))      // DStream transformation

      val pairs = words.map{line=>
        var seMap = collection.mutable.Map[String,String]()
        val random =scala.util.Random.nextInt.toString
        val state=if(random.toLong>0) "doing" else "finish"
        seMap += ("uid" -> random.toString)
        seMap += ("name" -> line)
        seMap += ("state" -> state)
        (line,seMap)
      }     // DStream transformation

      val mappingFunc = (word: String, count: Option[Int], state: State[Int]) => {
        if(state.isTimingOut()){
          System.out.println(word+" is timingout")
        }else{
          val sum = count.getOrElse(0) + state.getOption.getOrElse(0)
          val output = (word, sum)
          state.update(sum)
          output
        }
      }

      val stateDstream = pairs.mapWithState(StateSpec.function(mappingFunc).timeout(Seconds(60)))
      
      /**
        * checkpoint间隔一般设置为batchtime的5~10倍
        */
      stateDstream.checkpoint(Seconds(300))
      stateDstream.print(100)
      stateDstream.stateSnapshots().print()
      // DStream output
      // 上面 DStream transformation 构造出了 lines -> words -> pairs -> wordCounts -> .print() 这样一个 DStreamGraph
      // 但注意，到目前是定义好了产生数据的 SocketReceiver，以及一个 DStreamGraph，这些都是静态的
      ssc
    }

    //创建StreamingContext
    val ssc = StreamingContext.getOrCreate(checkpointDir,createStreamingContext)
    

    // 下面这行 start() 将在幕后启动 JobScheduler, 进而启动 JobGenerator 和 ReceiverTracker
    // ssc.start()
    //    -> JobScheduler.start()
    //        -> JobGenerator.start();    开始不断生成一个一个 batch
    //        -> ReceiverTracker.start(); 开始往 executor 上分布 ReceiverSupervisor 了，也会进一步创建和启动 Receiver
    ssc.start()

    // 然后用户 code 主线程就 block 在下面这行代码了
    // block 的后果就是，后台的 JobScheduler 线程周而复始的产生一个一个 batch 而不停息
    // 也就是在这里，我们前面静态定义的 DStreamGraph 的 print()，才一次一次被在 RDD 实例上调用，一次一次打印出当前 batch 的结果
    ssc.awaitTermination()
    
  }

}
